---
title: "jobsta"
subtitle: |
  | _Study - Job - Money_
  | 
  | Project for
  | Introduction to Semantic Systems
  | (188.399-2019W)
author: |
  | Group 01
  |
  | Cem Bicer (01425692)
  | Helmuth Breitenfellner (08725866)
  | Laszlo Kiraly (09227679)
  | Gerald Weber (00125536)
date: "2020-01-31"
output:
  beamer_presentation:
    theme: "Pittsburgh"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## App Idea

```{r logo, echo=FALSE, out.width="30%"}
knitr::include_graphics("jobsta-logo.png")
```

_Study - Job - Money_

* For Software Developers and Data Scientists
* Asks for experience, age, location
* Answers to following questions:
    * _What shall I study?_
    * _Where shall I work?_
    * _What shall I practise?_
    * _How can I improve?_

## The Mobile App

```{r fig.align="center", out.width="40%"}
knitr::include_graphics('mockup.png')
```

## Data Sources

* **Kaggle User Survey**$\hfill\break$
  Data Scientists, Country, Job Role, Programming Language, Income
* **StackOverflow User Survey**$\hfill\break$
  Software Developer, Country, Job Role, Programming Language, Income
* **GitHub Repositories Data**$\hfill\break$
  Repository URL, Popularity, Programming Language, Issues
* **TISS Lectures**$\hfill\break$
  Lectures, Lecturer, Description, Programming Language

## Ontology #1

```{r ontology, echo=FALSE, out.width="100%"}
knitr::include_graphics("ontology.png")
```

## Ontology #2

* Created with Protégé
* Reusing existing Ontologies
  * schema.org
  * dbpedia.org

## Kaggle Survey

* https://www.kaggle.com/c/kaggle-survey-2019
* Used Jupyter Notebook for Pre-Processing
* Created RDF XML directly from Python
* **Challenge:** high number of one-hot-encoded values, had to extract unique values

## StackOverflow Survey

* https://insights.stackoverflow.com/survey/2018
* Used Python for Pre-Processing
* Created RDF XML directly from Python
* **Challenge:** Fighting with OpenREFINE - at the end reverted to manual

## GitHub Repositories Data

* http://ghtorrent.org/
* Used Bash & R Script for Pre-Processing
* Created RDF XML directly from Python
* **Challenge:** _huge_ data archive (>100GB) had to be filtered / preprocessed

## TISS Lectures

* https://tiss.tuwien.ac.at/course/courseList.xhtml?dswid=6403&dsrid=238
* Used Python Script
* Created RDF XML directly from Python (using `rdflib`)
* **Challenge:** web scraping, identifying the programming language from text

## Mapping

How we harmonized data among the surveys

## SPARQL Queries #1

```
PREFIX group1: <http://www.semanticweb.org/sws/ws2019/group1#>
PREFIX schema: <http://schema.org/>
PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>
PREFIX dbpedia: <http://dbpedia.org/resource/>
PREFIX gr: <http://purl.org/goodrelations/v1#>
PREFIX sc: <http://purl.org/science/owl/sciencecommons/>

SELECT DISTINCT ?lecture ?language
WHERE {
  ?lecture group1:dealsWith ?language .
  ?developer group1:developsIn ?language .
  ?salaryRange group1:maxSalary ?salary .
  ?developer group1:hasSalaryRange ?salaryRange .
  ?developer schema:homeLocation dbpedia:Austria .
  FILTER (?salary > "150000"^^xsd:integer)
}
LIMIT 25
```

## SPARQL Queries #2

## Harmonize Data I

* Age Ranges
    * Different Age Ranges

* Salary and Salary Ranges
    * Salary Range in Kaggle
    * Salary Value in Stackoverflow

* Roles
  * Combined from Surveys into List
  * e.g. Frontend Developer -> Software Engineer
  * ... C-Suite Executive -> Manager

## Harmonize Data II

* Countries
    * dbpedia linked to external data

* Gender
    * Single Selection in Kaggle
    * Multiple Selections in Stackoverflow

* Computer Language
    * Combined from Surveys into List
    * Field in Github Repository
    * Extracted from TISS Lecture Description

## Lessons Learned


## Questions?
